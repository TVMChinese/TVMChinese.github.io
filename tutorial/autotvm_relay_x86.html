





<!DOCTYPE html>
<html class="writer-html5" lang="zh-CN" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Compiling and Optimizing a Model with the Python Interface (AutoTVM) &mdash; tvm 0.8.dev1961 文档</title>
  

  
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css" integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/gallery.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/tlcpack_theme.css" type="text/css" />

  
  
    <link rel="shortcut icon" href="../_static/tvm-logo-square.png"/>
  

  
  
  
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/translations.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <script type="text/javascript" src="../_static/js/tlcpack_theme.js"></script>
    <link rel="index" title="索引" href="../genindex.html" />
    <link rel="search" title="搜索" href="../search.html" />
    <link rel="next" title="使用张量表达式来处理运算符" href="tensor_expr_get_started.html" />
    <link rel="prev" title="使用TVMC编译和优化一个模型" href="tvmc_command_line_driver.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    
<header class="header">
    <div class="innercontainer">
      <div class="headerInner d-flex justify-content-between align-items-center">
          <div class="headerLogo">
               <a href="https://tvm.apache.org/"><img src=https://tvm.apache.org/assets/images/logo.svg alt="logo"></a>
          </div>

          <div id="headMenu" class="headerNav">
            <button type="button" id="closeHeadMenu" class="navCloseBtn"><img src="../_static/img/close-icon.svg" alt="Close"></button>
             <ul class="nav">
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/community>Community</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/download>Download</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/vta>VTA</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/blog>Blog</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/docs>Docs</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvmconf.org>Conference</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://github.com/apache/tvm/>Github</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvmchinese.github.io/declaration_zh_CN.html>About-Translators</a>
                </li>
             </ul>
               <div class="responsivetlcdropdown">
                 <button type="button" class="btn-link">
                   ASF
                 </button>
                 <ul>
                     <li>
                       <a href=https://apache.org/>Apache Homepage</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/licenses/>License</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/foundation/sponsorship.html>Sponsorship</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/security/>Security</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/foundation/thanks.html>Thanks</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/events/current-event>Events</a>
                     </li>
                     <li>
                       <a href=https://www.zhihu.com/column/c_1429578595417563136>Zhihu</a>
                     </li>
                 </ul>
               </div>
          </div>
            <div class="responsiveMenuIcon">
              <button type="button" id="menuBtn" class="btn-menu"><img src="../_static/img/menu-icon.svg" alt="Menu Icon"></button>
            </div>

            <div class="tlcDropdown">
              <div class="dropdown">
                <button type="button" class="btn-link dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                  ASF
                </button>
                <div class="dropdown-menu dropdown-menu-right">
                  <ul>
                     <li>
                       <a href=https://apache.org/>Apache Homepage</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/licenses/>License</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/foundation/sponsorship.html>Sponsorship</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/security/>Security</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/foundation/thanks.html>Thanks</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/events/current-event>Events</a>
                     </li>
                     <li>
                       <a href=https://www.zhihu.com/column/c_1429578595417563136>Zhihu</a>
                     </li>
                  </ul>
                </div>
              </div>
          </div>
       </div>
    </div>
 </header>
 
    <nav data-toggle="wy-nav-shift" class="wy-nav-side fixed">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html">
          

          
            
            <img src="../_static/tvm-logo-small.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
                <div class="version">
                  0.8.dev1961
                </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">如何开始</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../install/index.html">安装 TVM</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contribute/index.html">贡献者指南</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">用户引导</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="index.html">User Tutorial</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="introduction.html">介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="introduction.html#an-overview-of-tvm-and-model-optimization">TVM和模型优化的概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="install.html">安装 TVM</a></li>
<li class="toctree-l2"><a class="reference internal" href="tvmc_command_line_driver.html">使用TVMC编译和优化一个模型</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Compiling and Optimizing a Model with the Python Interface (AutoTVM)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#downloading-and-loading-the-onnx-model">Downloading and Loading the ONNX Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="#downloading-preprocessing-and-loading-the-test-image">Downloading, Preprocessing, and Loading the Test Image</a></li>
<li class="toctree-l3"><a class="reference internal" href="#compile-the-model-with-relay">Compile the Model With Relay</a></li>
<li class="toctree-l3"><a class="reference internal" href="#execute-on-the-tvm-runtime">Execute on the TVM Runtime</a></li>
<li class="toctree-l3"><a class="reference internal" href="#collect-basic-performance-data">Collect Basic Performance Data</a></li>
<li class="toctree-l3"><a class="reference internal" href="#postprocess-the-output">Postprocess the output</a></li>
<li class="toctree-l3"><a class="reference internal" href="#tune-the-model">Tune the model</a></li>
<li class="toctree-l3"><a class="reference internal" href="#compiling-an-optimized-model-with-tuning-data">使用调优数据编译一个优化后的模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="#comparing-the-tuned-and-untuned-models">比较调优和未调优的模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="#final-remarks">结语</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="tensor_expr_get_started.html">使用张量表达式来处理运算符</a></li>
<li class="toctree-l2"><a class="reference internal" href="autotvm_matmul_x86.html">Optimizing Operators with Schedule Templates and AutoTVM</a></li>
<li class="toctree-l2"><a class="reference internal" href="auto_scheduler_matmul_x86.html">Optimizing Operators with Auto-scheduling</a></li>
<li class="toctree-l2"><a class="reference internal" href="cross_compilation_and_rpc.html">Cross Compilation and RPC</a></li>
<li class="toctree-l2"><a class="reference internal" href="relay_quick_start.html">编译深度学习模型的快速开始教程</a></li>
<li class="toctree-l2"><a class="reference internal" href="intro_topi.html">Introduction to TOPI</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../how_to/index.html">How To Guides</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">开发者引导</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../dev/tutorial/index.html">Developer Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dev/how_to/how_to.html">开发者指南</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">架构指南</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../arch/index.html">Design and Architecture</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">主题引导</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../topic/microtvm/index.html">microTVM：裸机使用TVM</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topic/vta/index.html">VTA: Versatile Tensor Accelerator</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">参考指南</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../reference/langref/index.html">语言参考</a></li>
<li class="toctree-l1"><a class="reference internal" href="../reference/api/python/index.html">Python API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../reference/api/links.html">Other APIs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../reference/publications.html">Publications</a></li>
<li class="toctree-l1"><a class="reference internal" href="../genindex.html">索引</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      
      <nav class="wy-nav-top" aria-label="top navigation" data-toggle="wy-nav-top">
        
            <div class="togglemenu">

            </div>
            <div class="nav-content">
              <!-- tvm -->
              Table of content
            </div>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        

          




















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> <span class="br-arrow">></span></li>
        
          <li><a href="index.html">User Tutorial</a> <span class="br-arrow">></span></li>
        
      <li>Compiling and Optimizing a Model with the Python Interface (AutoTVM)</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/tutorial/autotvm_relay_x86.rst.txt" rel="nofollow"> <img src="../_static//img/source.svg" alt="viewsource"/></a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">注解</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-tutorial-autotvm-relay-x86-py"><span class="std std-ref">here</span></a> to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="compiling-and-optimizing-a-model-with-the-python-interface-autotvm">
<span id="sphx-glr-tutorial-autotvm-relay-x86-py"></span><h1>Compiling and Optimizing a Model with the Python Interface (AutoTVM)<a class="headerlink" href="#compiling-and-optimizing-a-model-with-the-python-interface-autotvm" title="永久链接至标题">¶</a></h1>
<p><strong>Author</strong>:
<a class="reference external" href="https://github.com/hogepodge">Chris Hoge</a></p>
<p>In the <a class="reference external" href="tvmc_command_line_driver">TVMC Tutorial</a>, we covered how to compile, run, and tune a
pre-trained vision model, ResNet-50-v2 using the command line interface for
TVM, TVMC. TVM is more that just a command-line tool though, it is an
optimizing framework with APIs available for a number of different languages
that gives you tremendous flexibility in working with machine learning models.</p>
<p>In this tutorial we will cover the same ground we did with TVMC, but show how
it is done with the Python API. Upon completion of this section, we will have
used the Python API for TVM to accomplish the following tasks:</p>
<ul class="simple">
<li><p>将一个预训练的ResNet50 V2模型编译为TVM运行时。</p></li>
<li><p>基于编译完成的模型运行一张真实的图片，并分析输出和模型的性能。</p></li>
<li><p>Tune the model that model on a CPU using TVM.</p></li>
<li><p>基于TVM收集的调优数据再编译一个优化后的模型。</p></li>
<li><p>基于优化后的模型运行一张真实的图片，并且对比输出和性能（这里是和未优化的模型进行对比）。</p></li>
</ul>
<p>The goal of this section is to give you an overview of TVM’s capabilites and
how to use them through the Python API.</p>
<p>TVM is a deep learning compiler framework, with a number of different modules
available for working with deep learning models and operators. In this
tutorial we will work through how to load, compile, and optimize a model
using the Python API.</p>
<p>We begin by importing a number of dependencies, including <code class="docutils literal notranslate"><span class="pre">onnx</span></code> for
loading and converting the model, helper utilities for downloading test data,
the Python Image Library for working with the image data, <code class="docutils literal notranslate"><span class="pre">numpy</span></code> for pre
and post-processing of the image data, the TVM Relay framework, and the TVM
Graph Executor.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">onnx</span>
<span class="kn">from</span> <span class="nn">tvm.contrib.download</span> <span class="k">import</span> <span class="n">download_testdata</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="k">import</span> <span class="n">Image</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">tvm.relay</span> <span class="k">as</span> <span class="nn">relay</span>
<span class="kn">import</span> <span class="nn">tvm</span>
<span class="kn">from</span> <span class="nn">tvm.contrib</span> <span class="k">import</span> <span class="n">graph_executor</span>
</pre></div>
</div>
<div class="section" id="downloading-and-loading-the-onnx-model">
<h2>Downloading and Loading the ONNX Model<a class="headerlink" href="#downloading-and-loading-the-onnx-model" title="永久链接至标题">¶</a></h2>
<p>For this tutorial, we will be working with ResNet-50 v2. ResNet-50 is a
convolutional neural network that is 50-layers deep and designed to classify
images. The model we will be using has been pre-trained on more than a
million images with 1000 different classifications. The network has an input
image size of 224x224. If you are interested exploring more of how the
ResNet-50 model is structured, we recommend downloading
<a class="reference external" href="https://netron.app">Netron</a>, a freely available ML model viewer.</p>
<p>TVM provides a helper library to download pre-trained models. By providing a
model URL, file name, and model type through the module, TVM will download
the model and save it to disk. For the instance of an ONNX model, you can
then load it into memory using the ONNX runtime.</p>
<div class="admonition note">
<p class="admonition-title">注解</p>
<p>Working with Other Model Formats</p>
<p>TVM supports many popular model formats. A list can be found in the <a class="reference external" href="https://tvm.apache.org/docs/tutorials/index.html#compile-deep-learning-models">Compile
Deep Learning Models</a>
section of the TVM Documentation.</p>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model_url</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="s2">&quot;https://github.com/onnx/models/raw/&quot;</span><span class="p">,</span>
        <span class="s2">&quot;master/vision/classification/resnet/model/&quot;</span><span class="p">,</span>
        <span class="s2">&quot;resnet50-v2-7.onnx&quot;</span><span class="p">,</span>
    <span class="p">]</span>
<span class="p">)</span>

<span class="n">model_path</span> <span class="o">=</span> <span class="n">download_testdata</span><span class="p">(</span><span class="n">model_url</span><span class="p">,</span> <span class="s2">&quot;resnet50-v2-7.onnx&quot;</span><span class="p">,</span> <span class="n">module</span><span class="o">=</span><span class="s2">&quot;onnx&quot;</span><span class="p">)</span>
<span class="n">onnx_model</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">model_path</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="downloading-preprocessing-and-loading-the-test-image">
<h2>Downloading, Preprocessing, and Loading the Test Image<a class="headerlink" href="#downloading-preprocessing-and-loading-the-test-image" title="永久链接至标题">¶</a></h2>
<p>Each model is particular when it comes to expected tensor shapes, formats and
data types. For this reason, most models require some pre and
post-processing, to ensure the input is valid and to interpret the output.
TVMC has adopted NumPy’s <code class="docutils literal notranslate"><span class="pre">.npz</span></code> format for both input and output data.</p>
<p>作为本教程的输入，我们将使用猫的图片，但你可以随意替换为任何你选择的图片。</p>
<a class="reference internal image-reference" href="https://s3.amazonaws.com/model-server/inputs/kitten.jpg"><img alt="https://s3.amazonaws.com/model-server/inputs/kitten.jpg" class="align-center" src="https://s3.amazonaws.com/model-server/inputs/kitten.jpg" style="width: 224px; height: 224px;" /></a>
<p>Download the image data, then convert it to a numpy array to use as an input to the model.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">img_url</span> <span class="o">=</span> <span class="s2">&quot;https://s3.amazonaws.com/model-server/inputs/kitten.jpg&quot;</span>
<span class="n">img_path</span> <span class="o">=</span> <span class="n">download_testdata</span><span class="p">(</span><span class="n">img_url</span><span class="p">,</span> <span class="s2">&quot;imagenet_cat.png&quot;</span><span class="p">,</span> <span class="n">module</span><span class="o">=</span><span class="s2">&quot;data&quot;</span><span class="p">)</span>

<span class="c1"># Resize it to 224x224</span>
<span class="n">resized_image</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">img_path</span><span class="p">)</span><span class="o">.</span><span class="n">resize</span><span class="p">((</span><span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">))</span>
<span class="n">img_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">resized_image</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span>

<span class="c1"># Our input image is in HWC layout while ONNX expects CHW input, so convert the array</span>
<span class="n">img_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">img_data</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

<span class="c1"># Normalize according to the ImageNet input specification</span>
<span class="n">imagenet_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">imagenet_stddev</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">norm_img_data</span> <span class="o">=</span> <span class="p">(</span><span class="n">img_data</span> <span class="o">/</span> <span class="mi">255</span> <span class="o">-</span> <span class="n">imagenet_mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">imagenet_stddev</span>

<span class="c1"># Add the batch dimension, as we are expecting 4-dimensional input: NCHW.</span>
<span class="n">img_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">norm_img_data</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="compile-the-model-with-relay">
<h2>Compile the Model With Relay<a class="headerlink" href="#compile-the-model-with-relay" title="永久链接至标题">¶</a></h2>
<p>The next step is to compile the ResNet model. We begin by importing the model
to relay using the <cite>from_onnx</cite> importer. We then build the model, with
standard optimizations, into a TVM library.  Finally, we create a TVM graph
runtime module from the library.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">target</span> <span class="o">=</span> <span class="s2">&quot;llvm&quot;</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">注解</p>
<p>定义正确的目标</p>
<p>Specifying the correct target can have a huge impact on the performance of
the compiled module, as it can take advantage of hardware features
available on the target. For more information, please refer to <a class="reference external" href="https://tvm.apache.org/docs/tutorials/autotvm/tune_relay_x86.html#define-network">Auto-tuning
a convolutional network for x86 CPU</a>.
We recommend identifying which CPU you are running, along with optional
features, and set the target appropriately. For example, for some
processors <code class="docutils literal notranslate"><span class="pre">target</span> <span class="pre">=</span> <span class="pre">&quot;llvm</span> <span class="pre">-mcpu=skylake&quot;</span></code>, or <code class="docutils literal notranslate"><span class="pre">target</span> <span class="pre">=</span> <span class="pre">&quot;llvm</span>
<span class="pre">-mcpu=skylake-avx512&quot;</span></code> for processors with the AVX-512 vector instruction
set.</p>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># The input name may vary across model types. You can use a tool</span>
<span class="c1"># like netron to check input names</span>
<span class="n">input_name</span> <span class="o">=</span> <span class="s2">&quot;data&quot;</span>
<span class="n">shape_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">input_name</span><span class="p">:</span> <span class="n">img_data</span><span class="o">.</span><span class="n">shape</span><span class="p">}</span>

<span class="n">mod</span><span class="p">,</span> <span class="n">params</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">frontend</span><span class="o">.</span><span class="n">from_onnx</span><span class="p">(</span><span class="n">onnx_model</span><span class="p">,</span> <span class="n">shape_dict</span><span class="p">)</span>

<span class="k">with</span> <span class="n">tvm</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">PassContext</span><span class="p">(</span><span class="n">opt_level</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
    <span class="n">lib</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="n">target</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">params</span><span class="p">)</span>

<span class="n">dev</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">target</span><span class="p">),</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">module</span> <span class="o">=</span> <span class="n">graph_executor</span><span class="o">.</span><span class="n">GraphModule</span><span class="p">(</span><span class="n">lib</span><span class="p">[</span><span class="s2">&quot;default&quot;</span><span class="p">](</span><span class="n">dev</span><span class="p">))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">输出:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>One or more operators have not been tuned. Please tune your model for better performance. Use DEBUG logging level to see more details.
</pre></div>
</div>
</div>
<div class="section" id="execute-on-the-tvm-runtime">
<h2>Execute on the TVM Runtime<a class="headerlink" href="#execute-on-the-tvm-runtime" title="永久链接至标题">¶</a></h2>
<p>Now that we’ve compiled the model, we can use the TVM runtime to make
predictions with it. To use TVM to run the model and make predictions, we
need two things:</p>
<ul class="simple">
<li><p>The compiled model, which we just produced.</p></li>
<li><p>模型进行预测的合法输入。</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dtype</span> <span class="o">=</span> <span class="s2">&quot;float32&quot;</span>
<span class="n">module</span><span class="o">.</span><span class="n">set_input</span><span class="p">(</span><span class="n">input_name</span><span class="p">,</span> <span class="n">img_data</span><span class="p">)</span>
<span class="n">module</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
<span class="n">output_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
<span class="n">tvm_output</span> <span class="o">=</span> <span class="n">module</span><span class="o">.</span><span class="n">get_output</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">tvm</span><span class="o">.</span><span class="n">nd</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">output_shape</span><span class="p">))</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="section" id="collect-basic-performance-data">
<h2>Collect Basic Performance Data<a class="headerlink" href="#collect-basic-performance-data" title="永久链接至标题">¶</a></h2>
<p>We want to collect some basic performance data associated with this
unoptimized model and compare it to a tuned model later. To help account for
CPU noise, we run the computation in multiple batches in multiple
repetitions, then gather some basis statistics on the mean, median, and
standard deviation.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">timeit</span>

<span class="n">timing_number</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">timing_repeat</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">unoptimized</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">timeit</span><span class="o">.</span><span class="n">Timer</span><span class="p">(</span><span class="k">lambda</span><span class="p">:</span> <span class="n">module</span><span class="o">.</span><span class="n">run</span><span class="p">())</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">repeat</span><span class="o">=</span><span class="n">timing_repeat</span><span class="p">,</span> <span class="n">number</span><span class="o">=</span><span class="n">timing_number</span><span class="p">))</span>
    <span class="o">*</span> <span class="mi">1000</span>
    <span class="o">/</span> <span class="n">timing_number</span>
<span class="p">)</span>
<span class="n">unoptimized</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;mean&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">unoptimized</span><span class="p">),</span>
    <span class="s2">&quot;median&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">unoptimized</span><span class="p">),</span>
    <span class="s2">&quot;std&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">unoptimized</span><span class="p">),</span>
<span class="p">}</span>

<span class="nb">print</span><span class="p">(</span><span class="n">unoptimized</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">输出:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>{&#39;mean&#39;: 181.74154901411384, &#39;median&#39;: 181.5139171667397, &#39;std&#39;: 0.7785952402085288}
</pre></div>
</div>
</div>
<div class="section" id="postprocess-the-output">
<h2>Postprocess the output<a class="headerlink" href="#postprocess-the-output" title="永久链接至标题">¶</a></h2>
<p>如前所述，每个模型都有自己特定的提供输出张量的方式。</p>
<p>In our case, we need to run some post-processing to render the outputs from
ResNet-50-V2 into a more human-readable form, using the lookup-table provided
for the model.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.special</span> <span class="k">import</span> <span class="n">softmax</span>

<span class="c1"># Download a list of labels</span>
<span class="n">labels_url</span> <span class="o">=</span> <span class="s2">&quot;https://s3.amazonaws.com/onnx-model-zoo/synset.txt&quot;</span>
<span class="n">labels_path</span> <span class="o">=</span> <span class="n">download_testdata</span><span class="p">(</span><span class="n">labels_url</span><span class="p">,</span> <span class="s2">&quot;synset.txt&quot;</span><span class="p">,</span> <span class="n">module</span><span class="o">=</span><span class="s2">&quot;data&quot;</span><span class="p">)</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">labels_path</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="n">l</span><span class="o">.</span><span class="n">rstrip</span><span class="p">()</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">f</span><span class="p">]</span>

<span class="c1"># Open the output and read the output tensor</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">softmax</span><span class="p">(</span><span class="n">tvm_output</span><span class="p">)</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
<span class="n">ranks</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">scores</span><span class="p">)[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="n">ranks</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">]:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;class=&#39;</span><span class="si">%s</span><span class="s2">&#39; with probability=</span><span class="si">%f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">labels</span><span class="p">[</span><span class="n">rank</span><span class="p">],</span> <span class="n">scores</span><span class="p">[</span><span class="n">rank</span><span class="p">]))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">输出:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>class=&#39;n02123045 tabby, tabby cat&#39; with probability=0.610551
class=&#39;n02123159 tiger cat&#39; with probability=0.367180
class=&#39;n02124075 Egyptian cat&#39; with probability=0.019365
class=&#39;n02129604 tiger, Panthera tigris&#39; with probability=0.001273
class=&#39;n04040759 radiator&#39; with probability=0.000261
</pre></div>
</div>
<p>This should produce the following output:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># class=&#39;n02123045 tabby, tabby cat&#39; with probability=0.610553</span>
<span class="c1"># class=&#39;n02123159 tiger cat&#39; with probability=0.367179</span>
<span class="c1"># class=&#39;n02124075 Egyptian cat&#39; with probability=0.019365</span>
<span class="c1"># class=&#39;n02129604 tiger, Panthera tigris&#39; with probability=0.001273</span>
<span class="c1"># class=&#39;n04040759 radiator&#39; with probability=0.000261</span>
</pre></div>
</div>
</div>
<div class="section" id="tune-the-model">
<h2>Tune the model<a class="headerlink" href="#tune-the-model" title="永久链接至标题">¶</a></h2>
<p>The previous model was compiled to work on the TVM runtime, but did not
include any platform specific optimization. In this section, we will show you
how to build an optimized model using TVM to target your working platform.</p>
<p>In some cases, we might not get the expected performance when running
inferences using our compiled module. In cases like this, we can make use of
the auto-tuner, to find a better configuration for our model and get a boost
in performance. Tuning in TVM refers to the process by which a model is
optimized to run faster on a given target. This differs from training or
fine-tuning in that it does not affect the accuracy of the model, but only
the runtime performance. As part of the tuning process, TVM will try running
many different operator implementation variants to see which perform best.
The results of these runs are stored in a tuning records file.</p>
<p>以最简形式，调优需要你提供三个东西：</p>
<ul class="simple">
<li><p>你打算将这个模型运行运行在哪个目标设备</p></li>
<li><p>the path to an output file in which the tuning records will be stored</p></li>
<li><p>要调整的模型的路径</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tvm.auto_scheduler</span> <span class="k">as</span> <span class="nn">auto_scheduler</span>
<span class="kn">from</span> <span class="nn">tvm.autotvm.tuner</span> <span class="k">import</span> <span class="n">XGBTuner</span>
<span class="kn">from</span> <span class="nn">tvm</span> <span class="k">import</span> <span class="n">autotvm</span>

<span class="c1"># Set up some basic parameters for the runner. The runner takes compiled code</span>
<span class="c1"># that is generated with a specific set of parameters and measures the</span>
<span class="c1"># performance of it. ``number`` specifies the number of different</span>
<span class="c1"># configurations that we will test, while ``repeat`` specifies how many</span>
<span class="c1"># measurements we will take of each configuration. ``min_repeat_ms`` is a value</span>
<span class="c1"># that specifies how long need to run configuration test. If the number of</span>
<span class="c1"># repeats falls under this time, it will be increased. This option is necessary</span>
<span class="c1"># for accurate tuning on GPUs, and is not required for CPU tuning. Setting this</span>
<span class="c1"># value to 0 disables it. The ``timeout`` places an upper limit on how long to</span>
<span class="c1"># run training code for each tested configuration.</span>

<span class="n">number</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">repeat</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">min_repeat_ms</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># since we&#39;re tuning on a CPU, can be set to 0</span>
<span class="n">timeout</span> <span class="o">=</span> <span class="mi">10</span>  <span class="c1"># in seconds</span>

<span class="c1"># create a TVM runner</span>
<span class="n">runner</span> <span class="o">=</span> <span class="n">autotvm</span><span class="o">.</span><span class="n">LocalRunner</span><span class="p">(</span>
    <span class="n">number</span><span class="o">=</span><span class="n">number</span><span class="p">,</span>
    <span class="n">repeat</span><span class="o">=</span><span class="n">repeat</span><span class="p">,</span>
    <span class="n">timeout</span><span class="o">=</span><span class="n">timeout</span><span class="p">,</span>
    <span class="n">min_repeat_ms</span><span class="o">=</span><span class="n">min_repeat_ms</span><span class="p">,</span>
    <span class="n">enable_cpu_cache_flush</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># Create a simple structure for holding tuning options. We use an XGBoost</span>
<span class="c1"># algorithim for guiding the search. For a production job, you will want to set</span>
<span class="c1"># the number of trials to be larger than the value of 10 used here. For CPU we</span>
<span class="c1"># recommend 1500, for GPU 3000-4000. The number of trials required can depend</span>
<span class="c1"># on the particular model and processor, so it&#39;s worth spending some time</span>
<span class="c1"># evaluating performance across a range of values to find the best balance</span>
<span class="c1"># between tuning time and model optimization. Because running tuning is time</span>
<span class="c1"># intensive we set number of trials to 10, but do not recommend a value this</span>
<span class="c1"># small. The ``early_stopping`` parameter is the minimum number of trails to</span>
<span class="c1"># run before a condition that stops the search early can be applied. The</span>
<span class="c1"># measure option indicates where trial code will be built, and where it will be</span>
<span class="c1"># run. In this case, we&#39;re using the ``LocalRunner`` we just created and a</span>
<span class="c1"># ``LocalBuilder``. The ``tuning_records`` option specifies a file to write</span>
<span class="c1"># the tuning data to.</span>

<span class="n">tuning_option</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;tuner&quot;</span><span class="p">:</span> <span class="s2">&quot;xgb&quot;</span><span class="p">,</span>
    <span class="s2">&quot;trials&quot;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span>
    <span class="s2">&quot;early_stopping&quot;</span><span class="p">:</span> <span class="mi">100</span><span class="p">,</span>
    <span class="s2">&quot;measure_option&quot;</span><span class="p">:</span> <span class="n">autotvm</span><span class="o">.</span><span class="n">measure_option</span><span class="p">(</span>
        <span class="n">builder</span><span class="o">=</span><span class="n">autotvm</span><span class="o">.</span><span class="n">LocalBuilder</span><span class="p">(</span><span class="n">build_func</span><span class="o">=</span><span class="s2">&quot;default&quot;</span><span class="p">),</span> <span class="n">runner</span><span class="o">=</span><span class="n">runner</span>
    <span class="p">),</span>
    <span class="s2">&quot;tuning_records&quot;</span><span class="p">:</span> <span class="s2">&quot;resnet-50-v2-autotuning.json&quot;</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">注解</p>
<p>定义调优搜索算法</p>
<p>By default this search is guided using an <cite>XGBoost Grid</cite> algorithm.
Depending on your model complexity and amount of time available, you might
want to choose a different algorithm.</p>
</div>
<div class="admonition note">
<p class="admonition-title">注解</p>
<p>Setting Tuning Parameters</p>
<p>In this example, in the interest of time, we set the number of trials and
early stopping to 10. You will likely see more performance improvements if
you set these values to be higher but this comes at the expense of time
spent tuning. The number of trials required for convergence will vary
depending on the specifics of the model and the target platform.</p>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># begin by extracting the taks from the onnx model</span>
<span class="n">tasks</span> <span class="o">=</span> <span class="n">autotvm</span><span class="o">.</span><span class="n">task</span><span class="o">.</span><span class="n">extract_from_program</span><span class="p">(</span><span class="n">mod</span><span class="p">[</span><span class="s2">&quot;main&quot;</span><span class="p">],</span> <span class="n">target</span><span class="o">=</span><span class="n">target</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">params</span><span class="p">)</span>

<span class="c1"># Tune the extracted tasks sequentially.</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">task</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">tasks</span><span class="p">):</span>
    <span class="n">prefix</span> <span class="o">=</span> <span class="s2">&quot;[Task </span><span class="si">%2d</span><span class="s2">/</span><span class="si">%2d</span><span class="s2">] &quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">tasks</span><span class="p">))</span>
    <span class="n">tuner_obj</span> <span class="o">=</span> <span class="n">XGBTuner</span><span class="p">(</span><span class="n">task</span><span class="p">,</span> <span class="n">loss_type</span><span class="o">=</span><span class="s2">&quot;rank&quot;</span><span class="p">)</span>
    <span class="n">tuner_obj</span><span class="o">.</span><span class="n">tune</span><span class="p">(</span>
        <span class="n">n_trial</span><span class="o">=</span><span class="nb">min</span><span class="p">(</span><span class="n">tuning_option</span><span class="p">[</span><span class="s2">&quot;trials&quot;</span><span class="p">],</span> <span class="nb">len</span><span class="p">(</span><span class="n">task</span><span class="o">.</span><span class="n">config_space</span><span class="p">)),</span>
        <span class="n">early_stopping</span><span class="o">=</span><span class="n">tuning_option</span><span class="p">[</span><span class="s2">&quot;early_stopping&quot;</span><span class="p">],</span>
        <span class="n">measure_option</span><span class="o">=</span><span class="n">tuning_option</span><span class="p">[</span><span class="s2">&quot;measure_option&quot;</span><span class="p">],</span>
        <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span>
            <span class="n">autotvm</span><span class="o">.</span><span class="n">callback</span><span class="o">.</span><span class="n">progress_bar</span><span class="p">(</span><span class="n">tuning_option</span><span class="p">[</span><span class="s2">&quot;trials&quot;</span><span class="p">],</span> <span class="n">prefix</span><span class="o">=</span><span class="n">prefix</span><span class="p">),</span>
            <span class="n">autotvm</span><span class="o">.</span><span class="n">callback</span><span class="o">.</span><span class="n">log_to_file</span><span class="p">(</span><span class="n">tuning_option</span><span class="p">[</span><span class="s2">&quot;tuning_records&quot;</span><span class="p">]),</span>
        <span class="p">],</span>
    <span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">输出:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[Task  1/25]  Current/Best:    0.00/   0.00 GFLOPS | Progress: (0/10) | 0.00 s
[Task  1/25]  Current/Best:   55.83/  55.83 GFLOPS | Progress: (10/10) | 14.81 s Done.

[Task  2/25]  Current/Best:    0.00/   0.00 GFLOPS | Progress: (0/10) | 0.00 s
[Task  2/25]  Current/Best:   36.24/  39.84 GFLOPS | Progress: (10/10) | 8.63 s Done.

[Task  3/25]  Current/Best:    0.00/   0.00 GFLOPS | Progress: (0/10) | 0.00 s
[Task  3/25]  Current/Best:   31.52/  48.26 GFLOPS | Progress: (10/10) | 12.62 s Done.

[Task  4/25]  Current/Best:    0.00/   0.00 GFLOPS | Progress: (0/10) | 0.00 s
[Task  4/25]  Current/Best:   14.85/  39.58 GFLOPS | Progress: (10/10) | 14.16 s Done.

[Task  5/25]  Current/Best:    0.00/   0.00 GFLOPS | Progress: (0/10) | 0.00 s
[Task  5/25]  Current/Best:   14.02/  42.88 GFLOPS | Progress: (10/10) | 6.19 s Done.

[Task  6/25]  Current/Best:    0.00/   0.00 GFLOPS | Progress: (0/10) | 0.00 s
[Task  6/25]  Current/Best:   30.41/  50.57 GFLOPS | Progress: (10/10) | 8.73 s Done.

[Task  7/25]  Current/Best:    0.00/   0.00 GFLOPS | Progress: (0/10) | 0.00 s
[Task  7/25]  Current/Best:   37.27/  60.57 GFLOPS | Progress: (10/10) | 7.99 s Done.

[Task  8/25]  Current/Best:    0.00/   0.00 GFLOPS | Progress: (0/10) | 0.00 s
[Task  8/25]  Current/Best:   41.00/  51.22 GFLOPS | Progress: (10/10) | 12.15 s Done.

[Task  9/25]  Current/Best:    0.00/   0.00 GFLOPS | Progress: (0/10) | 0.00 s
[Task  9/25]  Current/Best:   39.82/  39.82 GFLOPS | Progress: (10/10) | 10.51 s Done.

[Task 10/25]  Current/Best:    0.00/   0.00 GFLOPS | Progress: (0/10) | 0.00 s
[Task 10/25]  Current/Best:   16.01/  34.64 GFLOPS | Progress: (10/10) | 7.65 s Done.

[Task 11/25]  Current/Best:    0.00/   0.00 GFLOPS | Progress: (0/10) | 0.00 s
[Task 11/25]  Current/Best:   17.46/  47.65 GFLOPS | Progress: (10/10) | 6.41 s Done.

[Task 12/25]  Current/Best:    0.00/   0.00 GFLOPS | Progress: (0/10) | 0.00 s
[Task 12/25]  Current/Best:   25.46/  43.56 GFLOPS | Progress: (10/10) | 10.35 s Done.

[Task 13/25]  Current/Best:    0.00/   0.00 GFLOPS | Progress: (0/10) | 0.00 s
[Task 13/25]  Current/Best:   33.40/  56.68 GFLOPS | Progress: (10/10) | 9.48 s Done.

[Task 14/25]  Current/Best:    0.00/   0.00 GFLOPS | Progress: (0/10) | 0.00 s
[Task 14/25]  Current/Best:   27.01/  49.20 GFLOPS | Progress: (10/10) | 14.63 s Done.

[Task 15/25]  Current/Best:    0.00/   0.00 GFLOPS | Progress: (0/10) | 0.00 s
[Task 15/25]  Current/Best:   33.51/  45.45 GFLOPS | Progress: (10/10) | 13.96 s Done.

[Task 16/25]  Current/Best:    0.00/   0.00 GFLOPS | Progress: (0/10) | 0.00 s
[Task 16/25]  Current/Best:   25.41/  43.40 GFLOPS | Progress: (10/10) | 7.24 s Done.

[Task 17/25]  Current/Best:    0.00/   0.00 GFLOPS | Progress: (0/10) | 0.00 s
[Task 17/25]  Current/Best:   17.81/  53.40 GFLOPS | Progress: (10/10) | 9.05 s Done.

[Task 18/25]  Current/Best:    0.00/   0.00 GFLOPS | Progress: (0/10) | 0.00 s
[Task 18/25]  Current/Best:   45.64/  45.71 GFLOPS | Progress: (10/10) | 15.08 s Done.

[Task 19/25]  Current/Best:    0.00/   0.00 GFLOPS | Progress: (0/10) | 0.00 s
[Task 19/25]  Current/Best:   16.75/  48.80 GFLOPS | Progress: (10/10) | 12.78 s Done.

[Task 20/25]  Current/Best:    0.00/   0.00 GFLOPS | Progress: (0/10) | 0.00 s
[Task 20/25]  Current/Best:   15.65/  42.96 GFLOPS | Progress: (10/10) | 14.66 s Done.

[Task 21/25]  Current/Best:    0.00/   0.00 GFLOPS | Progress: (0/10) | 0.00 s
[Task 21/25]  Current/Best:   38.55/  48.57 GFLOPS | Progress: (10/10) | 14.02 s
[Task 22/25]  Current/Best:    0.00/   0.00 GFLOPS | Progress: (0/10) | 0.00 s Done.

[Task 22/25]  Current/Best:   42.10/  51.36 GFLOPS | Progress: (10/10) | 7.86 s Done.

[Task 23/25]  Current/Best:    0.00/   0.00 GFLOPS | Progress: (0/10) | 0.00 s
[Task 23/25]  Current/Best:   40.30/  50.14 GFLOPS | Progress: (10/10) | 9.61 s Done.

[Task 24/25]  Current/Best:    0.00/   0.00 GFLOPS | Progress: (0/10) | 0.00 s
[Task 24/25]  Current/Best:    4.16/   7.64 GFLOPS | Progress: (10/10) | 13.86 s
[Task 25/25]  Current/Best:    0.00/   0.00 GFLOPS | Progress: (0/10) | 0.00 s Done.

[Task 25/25]  Current/Best:    1.82/   2.66 GFLOPS | Progress: (10/10) | 14.44 s
</pre></div>
</div>
<p>The output from this tuning process will look something like this:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># [Task  1/24]  Current/Best:   10.71/  21.08 GFLOPS | Progress: (60/1000) | 111.77 s Done.</span>
<span class="c1"># [Task  1/24]  Current/Best:    9.32/  24.18 GFLOPS | Progress: (192/1000) | 365.02 s Done.</span>
<span class="c1"># [Task  2/24]  Current/Best:   22.39/ 177.59 GFLOPS | Progress: (960/1000) | 976.17 s Done.</span>
<span class="c1"># [Task  3/24]  Current/Best:   32.03/ 153.34 GFLOPS | Progress: (800/1000) | 776.84 s Done.</span>
<span class="c1"># [Task  4/24]  Current/Best:   11.96/ 156.49 GFLOPS | Progress: (960/1000) | 632.26 s Done.</span>
<span class="c1"># [Task  5/24]  Current/Best:   23.75/ 130.78 GFLOPS | Progress: (800/1000) | 739.29 s Done.</span>
<span class="c1"># [Task  6/24]  Current/Best:   38.29/ 198.31 GFLOPS | Progress: (1000/1000) | 624.51 s Done.</span>
<span class="c1"># [Task  7/24]  Current/Best:    4.31/ 210.78 GFLOPS | Progress: (1000/1000) | 701.03 s Done.</span>
<span class="c1"># [Task  8/24]  Current/Best:   50.25/ 185.35 GFLOPS | Progress: (972/1000) | 538.55 s Done.</span>
<span class="c1"># [Task  9/24]  Current/Best:   50.19/ 194.42 GFLOPS | Progress: (1000/1000) | 487.30 s Done.</span>
<span class="c1"># [Task 10/24]  Current/Best:   12.90/ 172.60 GFLOPS | Progress: (972/1000) | 607.32 s Done.</span>
<span class="c1"># [Task 11/24]  Current/Best:   62.71/ 203.46 GFLOPS | Progress: (1000/1000) | 581.92 s Done.</span>
<span class="c1"># [Task 12/24]  Current/Best:   36.79/ 224.71 GFLOPS | Progress: (1000/1000) | 675.13 s Done.</span>
<span class="c1"># [Task 13/24]  Current/Best:    7.76/ 219.72 GFLOPS | Progress: (1000/1000) | 519.06 s Done.</span>
<span class="c1"># [Task 14/24]  Current/Best:   12.26/ 202.42 GFLOPS | Progress: (1000/1000) | 514.30 s Done.</span>
<span class="c1"># [Task 15/24]  Current/Best:   31.59/ 197.61 GFLOPS | Progress: (1000/1000) | 558.54 s Done.</span>
<span class="c1"># [Task 16/24]  Current/Best:   31.63/ 206.08 GFLOPS | Progress: (1000/1000) | 708.36 s Done.</span>
<span class="c1"># [Task 17/24]  Current/Best:   41.18/ 204.45 GFLOPS | Progress: (1000/1000) | 736.08 s Done.</span>
<span class="c1"># [Task 18/24]  Current/Best:   15.85/ 222.38 GFLOPS | Progress: (980/1000) | 516.73 s Done.</span>
<span class="c1"># [Task 19/24]  Current/Best:   15.78/ 203.41 GFLOPS | Progress: (1000/1000) | 587.13 s Done.</span>
<span class="c1"># [Task 20/24]  Current/Best:   30.47/ 205.92 GFLOPS | Progress: (980/1000) | 471.00 s Done.</span>
<span class="c1"># [Task 21/24]  Current/Best:   46.91/ 227.99 GFLOPS | Progress: (308/1000) | 219.18 s Done.</span>
<span class="c1"># [Task 22/24]  Current/Best:   13.33/ 207.66 GFLOPS | Progress: (1000/1000) | 761.74 s Done.</span>
<span class="c1"># [Task 23/24]  Current/Best:   53.29/ 192.98 GFLOPS | Progress: (1000/1000) | 799.90 s Done.</span>
<span class="c1"># [Task 24/24]  Current/Best:   25.03/ 146.14 GFLOPS | Progress: (1000/1000) | 1112.55 s Done.</span>
</pre></div>
</div>
</div>
<div class="section" id="compiling-an-optimized-model-with-tuning-data">
<h2>使用调优数据编译一个优化后的模型<a class="headerlink" href="#compiling-an-optimized-model-with-tuning-data" title="永久链接至标题">¶</a></h2>
<p>As an output of the tuning process above, we obtained the tuning records
stored in <code class="docutils literal notranslate"><span class="pre">resnet-50-v2-autotuning.json</span></code>. The compiler will use the results to
generate high performance code for the model on your specified target.</p>
<p>现在我们已经收集了模型的调优数据，我们可以使用优化后的算子来重新编译模型以加快运算速度。</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">autotvm</span><span class="o">.</span><span class="n">apply_history_best</span><span class="p">(</span><span class="n">tuning_option</span><span class="p">[</span><span class="s2">&quot;tuning_records&quot;</span><span class="p">]):</span>
    <span class="k">with</span> <span class="n">tvm</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">PassContext</span><span class="p">(</span><span class="n">opt_level</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="p">{}):</span>
        <span class="n">lib</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="n">target</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">params</span><span class="p">)</span>

<span class="n">dev</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">target</span><span class="p">),</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">module</span> <span class="o">=</span> <span class="n">graph_executor</span><span class="o">.</span><span class="n">GraphModule</span><span class="p">(</span><span class="n">lib</span><span class="p">[</span><span class="s2">&quot;default&quot;</span><span class="p">](</span><span class="n">dev</span><span class="p">))</span>
</pre></div>
</div>
<p>验证优化后模型运行并产生相同的结果：</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dtype</span> <span class="o">=</span> <span class="s2">&quot;float32&quot;</span>
<span class="n">module</span><span class="o">.</span><span class="n">set_input</span><span class="p">(</span><span class="n">input_name</span><span class="p">,</span> <span class="n">img_data</span><span class="p">)</span>
<span class="n">module</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
<span class="n">output_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
<span class="n">tvm_output</span> <span class="o">=</span> <span class="n">module</span><span class="o">.</span><span class="n">get_output</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">tvm</span><span class="o">.</span><span class="n">nd</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">output_shape</span><span class="p">))</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

<span class="n">scores</span> <span class="o">=</span> <span class="n">softmax</span><span class="p">(</span><span class="n">tvm_output</span><span class="p">)</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
<span class="n">ranks</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">scores</span><span class="p">)[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="n">ranks</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">]:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;class=&#39;</span><span class="si">%s</span><span class="s2">&#39; with probability=</span><span class="si">%f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">labels</span><span class="p">[</span><span class="n">rank</span><span class="p">],</span> <span class="n">scores</span><span class="p">[</span><span class="n">rank</span><span class="p">]))</span>

<span class="c1"># Verifying that the predictions are the same:</span>
<span class="c1">#</span>
<span class="c1"># .. code-block:: bash</span>
<span class="c1">#</span>
<span class="c1">#   # class=&#39;n02123045 tabby, tabby cat&#39; with probability=0.610550</span>
<span class="c1">#   # class=&#39;n02123159 tiger cat&#39; with probability=0.367181</span>
<span class="c1">#   # class=&#39;n02124075 Egyptian cat&#39; with probability=0.019365</span>
<span class="c1">#   # class=&#39;n02129604 tiger, Panthera tigris&#39; with probability=0.001273</span>
<span class="c1">#   # class=&#39;n04040759 radiator&#39; with probability=0.000261</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">输出:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>class=&#39;n02123045 tabby, tabby cat&#39; with probability=0.610552
class=&#39;n02123159 tiger cat&#39; with probability=0.367180
class=&#39;n02124075 Egyptian cat&#39; with probability=0.019365
class=&#39;n02129604 tiger, Panthera tigris&#39; with probability=0.001273
class=&#39;n04040759 radiator&#39; with probability=0.000261
</pre></div>
</div>
</div>
<div class="section" id="comparing-the-tuned-and-untuned-models">
<h2>比较调优和未调优的模型<a class="headerlink" href="#comparing-the-tuned-and-untuned-models" title="永久链接至标题">¶</a></h2>
<p>We want to collect some basic performance data associated with this optimized
model to compare it to the unoptimized model. Depending on your underlying
hardware, number of iterations, and other factors, you should see a performance
improvement in comparing the optimized model to the unoptimized model.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">timeit</span>

<span class="n">timing_number</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">timing_repeat</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">optimized</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">timeit</span><span class="o">.</span><span class="n">Timer</span><span class="p">(</span><span class="k">lambda</span><span class="p">:</span> <span class="n">module</span><span class="o">.</span><span class="n">run</span><span class="p">())</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">repeat</span><span class="o">=</span><span class="n">timing_repeat</span><span class="p">,</span> <span class="n">number</span><span class="o">=</span><span class="n">timing_number</span><span class="p">))</span>
    <span class="o">*</span> <span class="mi">1000</span>
    <span class="o">/</span> <span class="n">timing_number</span>
<span class="p">)</span>
<span class="n">optimized</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;mean&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">optimized</span><span class="p">),</span> <span class="s2">&quot;median&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">optimized</span><span class="p">),</span> <span class="s2">&quot;std&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">optimized</span><span class="p">)}</span>


<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;optimized: </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">optimized</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;unoptimized: </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">unoptimized</span><span class="p">))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">输出:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>optimized: {&#39;mean&#39;: 150.72199111338705, &#39;median&#39;: 150.45831128954887, &#39;std&#39;: 0.8978831455478345}
unoptimized: {&#39;mean&#39;: 181.74154901411384, &#39;median&#39;: 181.5139171667397, &#39;std&#39;: 0.7785952402085288}
</pre></div>
</div>
</div>
<div class="section" id="final-remarks">
<h2>结语<a class="headerlink" href="#final-remarks" title="永久链接至标题">¶</a></h2>
<p>In this tutorial, we gave a short example of how to use the TVM Python API
to compile, run, and tune a model. We also discussed the need for pre and
post-processing of inputs and outputs. After the tuning process, we
demonstrated how to compare the performance of the unoptimized and optimize
models.</p>
<p>Here we presented a simple example using ResNet 50 V2 locally. However, TVM
supports many more features including cross-compilation, remote execution and
profiling/benchmarking.</p>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 6 minutes  53.955 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-tutorial-autotvm-relay-x86-py">
<div class="sphx-glr-download docutils container">
<p><a class="reference download internal" download="" href="../_downloads/57a45d9bef1af358191e7d50043e652c/autotvm_relay_x86.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">autotvm_relay_x86.py</span></code></a></p>
</div>
<div class="sphx-glr-download docutils container">
<p><a class="reference download internal" download="" href="../_downloads/2f91b1346a0ba21b800081aa15fdaac2/autotvm_relay_x86.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">autotvm_relay_x86.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>


           </div>
           
          </div>
          

<footer>

    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="tensor_expr_get_started.html" class="btn btn-neutral float-right" title="使用张量表达式来处理运算符" accesskey="n" rel="next">下一个 <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="tvmc_command_line_driver.html" class="btn btn-neutral float-left" title="使用TVMC编译和优化一个模型" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> 上一个</a>
      
    </div>

<div id="button" class="backtop"><img src="../_static//img/right.svg" alt="backtop"/> </div>
<section class="footerSec">
    <div class="footerHeader">
      <ul class="d-flex align-md-items-center justify-content-between flex-column flex-md-row">
        <li class="copywrite d-flex align-items-center">
          <h5 id="copy-right-info">© 2020 Apache Software Foundation | All right reserved</h5>
        </li>
      </ul>

    </div>

    <ul>
      <li class="footernote">Copyright © 2020 The Apache Software Foundation. Apache TVM, Apache, the Apache feather, and the Apache TVM project logo are either trademarks or registered trademarks of the Apache Software Foundation.</li>
    </ul>

</section>
</footer>
        </div>
      </div>

    </section>

  </div>
  

    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js" integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q" crossorigin="anonymous"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js" integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl" crossorigin="anonymous"></script>

  </body>
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
    <!-- Theme Analytics -->
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-75982049-2', 'auto');
    ga('send', 'pageview');
    </script>

    
   

</body>
</html>






<!DOCTYPE html>
<html class="writer-html5" lang="zh-CN" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>使用TVMC编译和优化一个模型 &mdash; tvm 0.8.dev1727+ga882350ea 文档</title>
  

  
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css" integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/gallery.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/tlcpack_theme.css" type="text/css" />

  
  
    <link rel="shortcut icon" href="../../_static/tvm-logo-square.png"/>
  

  
  
  
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/translations.js"></script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    
    <script type="text/javascript" src="../../_static/js/tlcpack_theme.js"></script>
    <link rel="index" title="索引" href="../../genindex.html" />
    <link rel="search" title="搜索" href="../../search.html" />
    <link rel="next" title="Compiling and Optimizing a Model with the Python Interface (AutoTVM)" href="autotvm_relay_x86.html" />
    <link rel="prev" title="安装 TVM" href="install.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    
<header class="header">
    <div class="innercontainer">
      <div class="headerInner d-flex justify-content-between align-items-center">
          <div class="headerLogo">
               <a href="https://tvm.apache.org/"><img src=https://tvm.apache.org/assets/images/logo.svg alt="logo"></a>
          </div>

          <div id="headMenu" class="headerNav">
            <button type="button" id="closeHeadMenu" class="navCloseBtn"><img src="../../_static/img/close-icon.svg" alt="Close"></button>
             <ul class="nav">
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/community>Community</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/download>Download</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/vta>VTA</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/blog>Blog</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/docs>Docs</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvmconf.org>Conference</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://github.com/apache/tvm/>Github</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvmchinese.github.io/declaration_zh_CN.html>Translate-Contribution</a>
                </li>
             </ul>
               <div class="responsivetlcdropdown">
                 <button type="button" class="btn-link">
                   ASF
                 </button>
                 <ul>
                     <li>
                       <a href=https://apache.org/>Apache Homepage</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/licenses/>License</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/foundation/sponsorship.html>Sponsorship</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/security/>Security</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/foundation/thanks.html>Thanks</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/events/current-event>Events</a>
                     </li>
                 </ul>
               </div>
          </div>
            <div class="responsiveMenuIcon">
              <button type="button" id="menuBtn" class="btn-menu"><img src="../../_static/img/menu-icon.svg" alt="Menu Icon"></button>
            </div>

            <div class="tlcDropdown">
              <div class="dropdown">
                <button type="button" class="btn-link dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                  ASF
                </button>
                <div class="dropdown-menu dropdown-menu-right">
                  <ul>
                     <li>
                       <a href=https://apache.org/>Apache Homepage</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/licenses/>License</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/foundation/sponsorship.html>Sponsorship</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/security/>Security</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/foundation/thanks.html>Thanks</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/events/current-event>Events</a>
                     </li>
                  </ul>
                </div>
              </div>
          </div>
       </div>
    </div>
 </header>
 
    <nav data-toggle="wy-nav-shift" class="wy-nav-side fixed">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html">
          

          
            
            <img src="../../_static/tvm-logo-small.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
                <div class="version">
                  0.8.dev1727+ga882350ea
                </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">引导</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../install/index.html">安装</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../contribute/index.html">为 TVM 做出贡献</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deploy/index.html">部署和集成</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dev/how_to.html">开发者指南</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../microtvm/index.html">microTVM：裸机使用TVM</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../errors.html">使用 TVM 时遇到 Errors 怎么做</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq.html">常见提问</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">教程</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">Getting Started With TVM</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="introduction.html">介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="introduction.html#an-overview-of-tvm-and-model-optimization">TVM和模型优化的概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="install.html">安装 TVM</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">使用TVMC编译和优化一个模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#using-tvmc">使用TVMC</a></li>
<li class="toctree-l3"><a class="reference internal" href="#obtaining-the-model">获取模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="#compiling-an-onnx-model-to-the-tvm-runtime">编译一个ONNX模型到TVM运行时</a></li>
<li class="toctree-l3"><a class="reference internal" href="#running-the-model-from-the-compiled-module-with-tvmc">Running the Model from The Compiled Module with TVMC</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#input-pre-processing">Input pre-processing</a></li>
<li class="toctree-l4"><a class="reference internal" href="#running-the-compiled-module">Running the Compiled Module</a></li>
<li class="toctree-l4"><a class="reference internal" href="#output-post-processing">Output Post-Processing</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#automatically-tuning-the-resnet-model">Automatically Tuning the ResNet Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="#compiling-an-optimized-model-with-tuning-data">Compiling an Optimized Model with Tuning Data</a></li>
<li class="toctree-l3"><a class="reference internal" href="#comparing-the-tuned-and-untuned-models">Comparing the Tuned and Untuned Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="#final-remarks">Final Remarks</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="autotvm_relay_x86.html">Compiling and Optimizing a Model with the Python Interface (AutoTVM)</a></li>
<li class="toctree-l2"><a class="reference internal" href="tensor_expr_get_started.html">使用张量表达式来处理运算符</a></li>
<li class="toctree-l2"><a class="reference internal" href="autotvm_matmul_x86.html">Optimizing Operators with Schedule Templates and AutoTVM</a></li>
<li class="toctree-l2"><a class="reference internal" href="auto_scheduler_matmul_x86.html">Optimizing Operators with Auto-scheduling</a></li>
<li class="toctree-l2"><a class="reference internal" href="cross_compilation_and_rpc.html">Cross Compilation and RPC</a></li>
<li class="toctree-l2"><a class="reference internal" href="relay_quick_start.html">编译深度学习模型的快速开始教程</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../index.html#compile-deep-learning-models">编译深度学习模型</a></li>
<li class="toctree-l1"><a class="reference internal" href="../index.html#tensor-expression-and-schedules">Tensor Expression and Schedules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../index.html#optimize-tensor-operators">Optimize Tensor Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="../index.html#autotvm-template-based-auto-tuning">AutoTVM : Template-based Auto Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../index.html#autoscheduler-template-free-auto-scheduling">AutoScheduler : Template-free Auto Scheduling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../index.html#developer-tutorials">Developer Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../index.html#topi-tvm-operator-inventory">TOPI: TVM Operator Inventory</a></li>
<li class="toctree-l1"><a class="reference internal" href="../index.html#microtvm">microTVM</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">参考</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../langref/index.html">语言参考</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/python/index.html">Python API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/links.html">其它 API 参考链接</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">深入</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../dev/index.html">Design and Architecture</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">杂项</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../vta/index.html">VTA: Deep Learning Accelerator Stack</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../profiling/index.html">Profiling Deep Learning Models</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../genindex.html">索引</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      
      <nav class="wy-nav-top" aria-label="top navigation" data-toggle="wy-nav-top">
        
            <div class="togglemenu">

            </div>
            <div class="nav-content">
              <!-- tvm -->
              Table of content
            </div>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        

          




















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html">Docs</a> <span class="br-arrow">></span></li>
        
          <li><a href="../index.html">Getting Started With TVM</a> <span class="br-arrow">></span></li>
        
      <li>使用TVMC编译和优化一个模型</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../../_sources/tutorials/get_started/tvmc_command_line_driver.rst.txt" rel="nofollow"> <img src="../../_static//img/source.svg" alt="viewsource"/></a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">注解</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-tutorials-get-started-tvmc-command-line-driver-py"><span class="std std-ref">here</span></a> to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="compiling-and-optimizing-a-model-with-tvmc">
<span id="sphx-glr-tutorials-get-started-tvmc-command-line-driver-py"></span><h1>使用TVMC编译和优化一个模型<a class="headerlink" href="#compiling-and-optimizing-a-model-with-tvmc" title="永久链接至标题">¶</a></h1>
<p><strong>Authors</strong>:
<a class="reference external" href="https://github.com/leandron">Leandro Nunes</a>,
<a class="reference external" href="https://github.com/mbaret">Matthew Barrett</a>,
<a class="reference external" href="https://github.com/hogepodge">Chris Hoge</a></p>
<p>在这个教程中，我们将使用TVMC（TVM命令行驱动程序）。TVMC是一个将TVM的一些特性比如自动调优，编译，分析和运行模型等通过命令行前端暴露出来的工具。</p>
<p>在本教程中，我们会基于TVMC完成以下任务：</p>
<ul class="simple">
<li><p>将一个预训练的ResNet50 V2模型编译为TVM运行时。</p></li>
<li><p>基于编译完成的模型运行一张真实的图片，并分析输出和模型的性能。</p></li>
<li><p>使用TVM在CPU上对模型调优。</p></li>
<li><p>基于TVM收集的调优数据再编译一个优化后的模型。</p></li>
<li><p>基于优化后的模型运行一张真实的图片，并且对比输出和性能（这里是和未优化的模型进行对比）。</p></li>
</ul>
<p>这一节的目标是向你概述TVM和TVMC的功能，并为了解TVM的工作原理奠定基础。</p>
<div class="section" id="using-tvmc">
<h2>使用TVMC<a class="headerlink" href="#using-tvmc" title="永久链接至标题">¶</a></h2>
<p>TVMC是一个Python应用程序，是TVM Python包的一部分。当你使用Python包安装TVM时，您将获得一个叫作``tvmc``的命令行应用程序。此命令的位置将根据你的平台和安装方法而各有不同。</p>
<p>或者，如果你将TVM编译为在``$PYTHONPATH`` 中的Python模块，你可以通过下面的命令来启动TVMC命令行驱动程序`python -m tvm.driver.tvmc``。</p>
<p>简单起见，本教程以``tvmc <a href="#id1"><span class="problematic" id="id2">``</span></a>的方式提起TVMC命令行，但使用``python -m tvm.driver.tvmc <a href="#id3"><span class="problematic" id="id4">``</span></a>可以获得相同的结果。</p>
<p>你可以使用以下方法查看帮助页面：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>tvmc --help
</pre></div>
</div>
<p>The main features of TVM available to <code class="docutils literal notranslate"><span class="pre">tvmc</span></code> are from subcommands
<code class="docutils literal notranslate"><span class="pre">compile</span></code>, and <code class="docutils literal notranslate"><span class="pre">run</span></code>, and <code class="docutils literal notranslate"><span class="pre">tune</span></code>.  To read about specific options under
a given subcommand, use <code class="docutils literal notranslate"><span class="pre">tvmc</span> <span class="pre">&lt;subcommand&gt;</span> <span class="pre">--help</span></code>. We will cover each of
these commands in this tutorial, but first we need to download a pre-trained
model to work with.</p>
</div>
<div class="section" id="obtaining-the-model">
<h2>获取模型<a class="headerlink" href="#obtaining-the-model" title="永久链接至标题">¶</a></h2>
<p>在本教程中，我们将使用ResNet-50 v2。ResNet-50是一个深度为50层的卷积神经网络，被用于图像分类。我们将要使用的模型已经在超过100万张具有1000种的不同分类图像上进行了预训练。该网络的输入大小是224x224。如果你对ResNet-50的结构很感兴趣，我们建议你下载 <cite>Netron &lt;https://netron.app&gt;</cite>,它是一款免费的ML模型可视化软件。</p>
<p>在本教程中，我们将使用ONNX格式的模型。</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>wget https://github.com/onnx/models/raw/master/vision/classification/resnet/model/resnet50-v2-7.onnx
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">注解</p>
<p>已支持的模型格式。</p>
<p>TVMC支持使用Keras，ONNX，TensorFlow，TFLite和Torch创建的模型。如果你需要明确提供你正在使用的模型格式，请使用选项``–model-format``。 有关更多信息，请参阅“tvmc compile –help”。</p>
</div>
<div class="admonition note">
<p class="admonition-title">注解</p>
<p>给TVM添加ONNX支持</p>
<p>TVM依赖于你系统上有可用的ONNX Python库。你可以使用命令``pip3 install –user onnx``来安装ONNX。如果你具有root权限并且想全局安装ONNX，则可以删除``–user`` 选项。</p>
</div>
</div>
<div class="section" id="compiling-an-onnx-model-to-the-tvm-runtime">
<h2>编译一个ONNX模型到TVM运行时<a class="headerlink" href="#compiling-an-onnx-model-to-the-tvm-runtime" title="永久链接至标题">¶</a></h2>
<p>一旦我们下载好ResNet-50模型，下一步就是编译它。需要调用``tvmc compile``.来实现它。从编译过程中获得的输出是一个将模型编译为目标平台动态库的TAR包。我们可以使用TVM运行时在的目标设备上运行该模型。</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>tvmc compile <span class="se">\</span>
--target <span class="s2">&quot;llvm&quot;</span> <span class="se">\</span>
--output resnet50-v2-7-tvm.tar <span class="se">\</span>
resnet50-v2-7.onnx
</pre></div>
</div>
<p>我们来看看 <code class="docutils literal notranslate"><span class="pre">tvmc</span> <span class="pre">compile</span></code> 在模块中创建的文件：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>mkdir model
tar -xvf resnet50-v2-7-tvm.tar -C model
ls model
</pre></div>
</div>
<p>你将看到列出的三个文件。</p>
<ul class="simple">
<li><p><cite>mod.so`</cite> 是模型，用一个可以由TVM运行时加载的C++库来表示。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mod.json</span></code> is a text representation of the TVM Relay computation graph.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mod.params</span></code> is a file containing the parameters for the pre-trained
model.</p></li>
</ul>
<p>This module can be directly loaded by your application, and the model can be
run via the TVM runtime APIs.</p>
<div class="admonition note">
<p class="admonition-title">注解</p>
<p>Defining the Correct Target</p>
<p>Specifying the correct target (option <code class="docutils literal notranslate"><span class="pre">--target</span></code>) can have a huge
impact on the performance of the compiled module, as it can take
advantage of hardware features available on the target. For more
information, please refer to <a class="reference external" href="https://tvm.apache.org/docs/tutorials/autotvm/tune_relay_x86.html#define-network">Auto-tuning a convolutional network
for x86 CPU</a>.
We recommend identifying which CPU you are running, along with optional features,
and set the target appropriately.</p>
</div>
</div>
<div class="section" id="running-the-model-from-the-compiled-module-with-tvmc">
<h2>Running the Model from The Compiled Module with TVMC<a class="headerlink" href="#running-the-model-from-the-compiled-module-with-tvmc" title="永久链接至标题">¶</a></h2>
<p>Now that we’ve compiled the model to this module, we can use the TVM runtime
to make predictions with it. TVMC has the TVM runtime built in to it,
allowing you to run compiled TVM models. To use TVMC to run the model and
make predictions, we need two things:</p>
<ul class="simple">
<li><p>The compiled module, which we just produced.</p></li>
<li><p>Valid input to the model to make predictions on.</p></li>
</ul>
<p>Each model is particular when it comes to expected tensor shapes, formats and
data types. For this reason, most models require some pre and
post-processing, to ensure the input is valid and to interpret the output.
TVMC has adopted NumPy’s <code class="docutils literal notranslate"><span class="pre">.npz</span></code> format for both input and output data. This
is a well-supported NumPy format to serialize multiple arrays into a file</p>
<p>As input for this tutorial, we will use the image of a cat, but you can feel
free to substitute image for any of your choosing.</p>
<a class="reference internal image-reference" href="https://s3.amazonaws.com/model-server/inputs/kitten.jpg"><img alt="https://s3.amazonaws.com/model-server/inputs/kitten.jpg" class="align-center" src="https://s3.amazonaws.com/model-server/inputs/kitten.jpg" style="width: 224px; height: 224px;" /></a>
<div class="section" id="input-pre-processing">
<h3>Input pre-processing<a class="headerlink" href="#input-pre-processing" title="永久链接至标题">¶</a></h3>
<p>For our ResNet 50 V2 model, the input is expected to be in ImageNet format.
Here is an example of a script to pre-process an image for ResNet 50 V2.</p>
<p>You will need to have a supported version of the Python Image Library
installed. You can use <code class="docutils literal notranslate"><span class="pre">pip3</span> <span class="pre">install</span> <span class="pre">--user</span> <span class="pre">pillow</span></code> to satisfy this
requirement for the script.</p>
<div class="literal-block-wrapper docutils container" id="preprocess-py">
<div class="code-block-caption"><span class="caption-text">preprocess.py</span><a class="headerlink" href="#preprocess-py" title="永久链接至代码">¶</a></div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span> <span class="c1">#!python ./preprocess.py</span>
 <span class="kn">from</span> <span class="nn">tvm.contrib.download</span> <span class="kn">import</span> <span class="n">download_testdata</span>
 <span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
 <span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

 <span class="n">img_url</span> <span class="o">=</span> <span class="s2">&quot;https://s3.amazonaws.com/model-server/inputs/kitten.jpg&quot;</span>
 <span class="n">img_path</span> <span class="o">=</span> <span class="n">download_testdata</span><span class="p">(</span><span class="n">img_url</span><span class="p">,</span> <span class="s2">&quot;imagenet_cat.png&quot;</span><span class="p">,</span> <span class="n">module</span><span class="o">=</span><span class="s2">&quot;data&quot;</span><span class="p">)</span>

 <span class="c1"># Resize it to 224x224</span>
 <span class="n">resized_image</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">img_path</span><span class="p">)</span><span class="o">.</span><span class="n">resize</span><span class="p">((</span><span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">))</span>
 <span class="n">img_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">resized_image</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span>

 <span class="c1"># ONNX expects NCHW input, so convert the array</span>
 <span class="n">img_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">img_data</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

 <span class="c1"># Normalize according to ImageNet</span>
 <span class="n">imagenet_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">])</span>
 <span class="n">imagenet_stddev</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">])</span>
 <span class="n">norm_img_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">img_data</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span>
 <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">img_data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
         <span class="n">norm_img_data</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span> <span class="o">=</span> <span class="p">(</span><span class="n">img_data</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span> <span class="o">/</span> <span class="mi">255</span> <span class="o">-</span> <span class="n">imagenet_mean</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">/</span> <span class="n">imagenet_stddev</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

 <span class="c1"># Add batch dimension</span>
 <span class="n">img_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">norm_img_data</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

 <span class="c1"># Save to .npz (outputs imagenet_cat.npz)</span>
 <span class="n">np</span><span class="o">.</span><span class="n">savez</span><span class="p">(</span><span class="s2">&quot;imagenet_cat&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">img_data</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="running-the-compiled-module">
<h3>Running the Compiled Module<a class="headerlink" href="#running-the-compiled-module" title="永久链接至标题">¶</a></h3>
<p>With both the model and input data in hand, we can now run TVMC to make a
prediction:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>tvmc run <span class="se">\</span>
--inputs imagenet_cat.npz <span class="se">\</span>
--output predictions.npz <span class="se">\</span>
resnet50-v2-7-tvm.tar
</pre></div>
</div>
<p>Recall that the <cite>.tar</cite> model file includes a C++ library, a description of
the Relay model, and the parameters for the model. TVMC includes the TVM
runtime, which can load the model and make predictions against input. When
running the above command, TVMC outputs a new file, <code class="docutils literal notranslate"><span class="pre">predictions.npz</span></code>, that
contains the model output tensors in NumPy format.</p>
<p>In this example, we are running the model on the same machine that we used
for compilation. In some cases we might want to run it remotely via an RPC
Tracker. To read more about these options please check <code class="docutils literal notranslate"><span class="pre">tvmc</span> <span class="pre">run</span> <span class="pre">--help</span></code>.</p>
</div>
<div class="section" id="output-post-processing">
<h3>Output Post-Processing<a class="headerlink" href="#output-post-processing" title="永久链接至标题">¶</a></h3>
<p>As previously mentioned, each model will have its own particular way of
providing output tensors.</p>
<p>In our case, we need to run some post-processing to render the outputs from
ResNet 50 V2 into a more human-readable form, using the lookup-table provided
for the model.</p>
<p>The script below shows an example of the post-processing to extract labels
from the output of our compiled module.</p>
<div class="literal-block-wrapper docutils container" id="postprocess-py">
<div class="code-block-caption"><span class="caption-text">postprocess.py</span><a class="headerlink" href="#postprocess-py" title="永久链接至代码">¶</a></div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="ch">#!python ./postprocess.py</span>
<span class="kn">import</span> <span class="nn">os.path</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">scipy.special</span> <span class="kn">import</span> <span class="n">softmax</span>

<span class="kn">from</span> <span class="nn">tvm.contrib.download</span> <span class="kn">import</span> <span class="n">download_testdata</span>

<span class="c1"># Download a list of labels</span>
<span class="n">labels_url</span> <span class="o">=</span> <span class="s2">&quot;https://s3.amazonaws.com/onnx-model-zoo/synset.txt&quot;</span>
<span class="n">labels_path</span> <span class="o">=</span> <span class="n">download_testdata</span><span class="p">(</span><span class="n">labels_url</span><span class="p">,</span> <span class="s2">&quot;synset.txt&quot;</span><span class="p">,</span> <span class="n">module</span><span class="o">=</span><span class="s2">&quot;data&quot;</span><span class="p">)</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">labels_path</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="n">l</span><span class="o">.</span><span class="n">rstrip</span><span class="p">()</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">f</span><span class="p">]</span>

<span class="n">output_file</span> <span class="o">=</span> <span class="s2">&quot;predictions.npz&quot;</span>

<span class="c1"># Open the output and read the output tensor</span>
<span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">output_file</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">output_file</span><span class="p">)</span> <span class="k">as</span> <span class="n">data</span><span class="p">:</span>
        <span class="n">scores</span> <span class="o">=</span> <span class="n">softmax</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;output_0&quot;</span><span class="p">])</span>
        <span class="n">scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
        <span class="n">ranks</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">scores</span><span class="p">)[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

        <span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="n">ranks</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">]:</span>
            <span class="k">print</span><span class="p">(</span><span class="s2">&quot;class=&#39;</span><span class="si">%s</span><span class="s2">&#39; with probability=</span><span class="si">%f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">labels</span><span class="p">[</span><span class="n">rank</span><span class="p">],</span> <span class="n">scores</span><span class="p">[</span><span class="n">rank</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<p>Running this script should produce the following output:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python postprocess.py

<span class="c1"># class=&#39;n02123045 tabby, tabby cat&#39; with probability=0.610553</span>
<span class="c1"># class=&#39;n02123159 tiger cat&#39; with probability=0.367179</span>
<span class="c1"># class=&#39;n02124075 Egyptian cat&#39; with probability=0.019365</span>
<span class="c1"># class=&#39;n02129604 tiger, Panthera tigris&#39; with probability=0.001273</span>
<span class="c1"># class=&#39;n04040759 radiator&#39; with probability=0.000261</span>
</pre></div>
</div>
<p>Try replacing the cat image with other images, and see what sort of
predictions the ResNet model makes.</p>
</div>
</div>
<div class="section" id="automatically-tuning-the-resnet-model">
<h2>Automatically Tuning the ResNet Model<a class="headerlink" href="#automatically-tuning-the-resnet-model" title="永久链接至标题">¶</a></h2>
<p>The previous model was compiled to work on the TVM runtime, but did not
include any platform specific optimization. In this section, we will show you
how to build an optimized model using TVMC to target your working platform.</p>
<p>In some cases, we might not get the expected performance when running
inferences using our compiled module.  In cases like this, we can make use of
the auto-tuner, to find a better configuration for our model and get a boost
in performance. Tuning in TVM refers to the process by which a model is
optimized to run faster on a given target. This differs from training or
fine-tuning in that it does not affect the accuracy of the model, but only
the runtime performance. As part of the tuning process, TVM will try running
many different operator implementation variants to see which perform best.
The results of these runs are stored in a tuning records file, which is
ultimately the output of the <code class="docutils literal notranslate"><span class="pre">tune</span></code> subcommand.</p>
<p>In the simplest form, tuning requires you to provide three things:</p>
<ul class="simple">
<li><p>the target specification of the device you intend to run this model on</p></li>
<li><p>the path to an output file in which the tuning records will be stored, and
finally</p></li>
<li><p>a path to the model to be tuned.</p></li>
</ul>
<p>The example below demonstrates how that works in practice:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>tvmc tune <span class="se">\</span>
--target <span class="s2">&quot;llvm&quot;</span> <span class="se">\</span>
--output resnet50-v2-7-autotuner_records.json <span class="se">\</span>
resnet50-v2-7.onnx
</pre></div>
</div>
<p>In this example, you will see better results if you indicate a more specific
target for the <cite>–target</cite> flag.  For example, on an Intel i7 processor you
could use <cite>–target llvm -mcpu=skylake</cite>. For this tuning example, we are
tuning locally on the CPU using LLVM as the compiler for the specified
achitecture.</p>
<p>TVMC will perform a search against the parameter space for the model, trying
out different configurations for operators and choosing the one that runs
fastest on your platform. Although this is a guided search based on the CPU
and model operations, it can still take several hours to complete the search.
The output of this search will be saved to the
<cite>resnet50-v2-7-autotuner_records.json</cite> file, which will later be used to
compile an optimized model.</p>
<div class="admonition note">
<p class="admonition-title">注解</p>
<p>Defining the Tuning Search Algorithm</p>
<p>By default this search is guided using an <cite>XGBoost Grid</cite> algorithm.
Depending on your model complexity and amount of time avilable, you might
want to choose a different algorithm. A full list is available by
consulting <code class="docutils literal notranslate"><span class="pre">tvmc</span> <span class="pre">tune</span> <span class="pre">--help</span></code>.</p>
</div>
<p>The output will look something like this for a consumer-level Skylake CPU:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>tvmc tune   --target <span class="s2">&quot;llvm -mcpu=broadwell&quot;</span>   --output resnet50-v2-7-autotuner_records.json   resnet50-v2-7.onnx
<span class="c1"># [Task  1/24]  Current/Best:    9.65/  23.16 GFLOPS | Progress: (60/1000) | 130.74 s Done.</span>
<span class="c1"># [Task  1/24]  Current/Best:    3.56/  23.16 GFLOPS | Progress: (192/1000) | 381.32 s Done.</span>
<span class="c1"># [Task  2/24]  Current/Best:   13.13/  58.61 GFLOPS | Progress: (960/1000) | 1190.59 s Done.</span>
<span class="c1"># [Task  3/24]  Current/Best:   31.93/  59.52 GFLOPS | Progress: (800/1000) | 727.85 s Done.</span>
<span class="c1"># [Task  4/24]  Current/Best:   16.42/  57.80 GFLOPS | Progress: (960/1000) | 559.74 s Done.</span>
<span class="c1"># [Task  5/24]  Current/Best:   12.42/  57.92 GFLOPS | Progress: (800/1000) | 766.63 s Done.</span>
<span class="c1"># [Task  6/24]  Current/Best:   20.66/  59.25 GFLOPS | Progress: (1000/1000) | 673.61 s Done.</span>
<span class="c1"># [Task  7/24]  Current/Best:   15.48/  59.60 GFLOPS | Progress: (1000/1000) | 953.04 s Done.</span>
<span class="c1"># [Task  8/24]  Current/Best:   31.97/  59.33 GFLOPS | Progress: (972/1000) | 559.57 s Done.</span>
<span class="c1"># [Task  9/24]  Current/Best:   34.14/  60.09 GFLOPS | Progress: (1000/1000) | 479.32 s Done.</span>
<span class="c1"># [Task 10/24]  Current/Best:   12.53/  58.97 GFLOPS | Progress: (972/1000) | 642.34 s Done.</span>
<span class="c1"># [Task 11/24]  Current/Best:   30.94/  58.47 GFLOPS | Progress: (1000/1000) | 648.26 s Done.</span>
<span class="c1"># [Task 12/24]  Current/Best:   23.66/  58.63 GFLOPS | Progress: (1000/1000) | 851.59 s Done.</span>
<span class="c1"># [Task 13/24]  Current/Best:   25.44/  59.76 GFLOPS | Progress: (1000/1000) | 534.58 s Done.</span>
<span class="c1"># [Task 14/24]  Current/Best:   26.83/  58.51 GFLOPS | Progress: (1000/1000) | 491.67 s Done.</span>
<span class="c1"># [Task 15/24]  Current/Best:   33.64/  58.55 GFLOPS | Progress: (1000/1000) | 529.85 s Done.</span>
<span class="c1"># [Task 16/24]  Current/Best:   14.93/  57.94 GFLOPS | Progress: (1000/1000) | 645.55 s Done.</span>
<span class="c1"># [Task 17/24]  Current/Best:   28.70/  58.19 GFLOPS | Progress: (1000/1000) | 756.88 s Done.</span>
<span class="c1"># [Task 18/24]  Current/Best:   19.01/  60.43 GFLOPS | Progress: (980/1000) | 514.69 s Done.</span>
<span class="c1"># [Task 19/24]  Current/Best:   14.61/  57.30 GFLOPS | Progress: (1000/1000) | 614.44 s Done.</span>
<span class="c1"># [Task 20/24]  Current/Best:   10.47/  57.68 GFLOPS | Progress: (980/1000) | 479.80 s Done.</span>
<span class="c1"># [Task 21/24]  Current/Best:   34.37/  58.28 GFLOPS | Progress: (308/1000) | 225.37 s Done.</span>
<span class="c1"># [Task 22/24]  Current/Best:   15.75/  57.71 GFLOPS | Progress: (1000/1000) | 1024.05 s Done.</span>
<span class="c1"># [Task 23/24]  Current/Best:   23.23/  58.92 GFLOPS | Progress: (1000/1000) | 999.34 s Done.</span>
<span class="c1"># [Task 24/24]  Current/Best:   17.27/  55.25 GFLOPS | Progress: (1000/1000) | 1428.74 s Done.</span>
</pre></div>
</div>
<p>Tuning sessions can take a long time, so <code class="docutils literal notranslate"><span class="pre">tvmc</span> <span class="pre">tune</span></code> offers many options to customize your tuning
process, in terms of number of repetitions (<code class="docutils literal notranslate"><span class="pre">--repeat</span></code> and <code class="docutils literal notranslate"><span class="pre">--number</span></code>, for example), the tuning
algorithm to be used, and so on. Check <code class="docutils literal notranslate"><span class="pre">tvmc</span> <span class="pre">tune</span> <span class="pre">--help</span></code> for more information.</p>
</div>
<div class="section" id="compiling-an-optimized-model-with-tuning-data">
<h2>Compiling an Optimized Model with Tuning Data<a class="headerlink" href="#compiling-an-optimized-model-with-tuning-data" title="永久链接至标题">¶</a></h2>
<p>As an output of the tuning process above, we obtained the tuning records
stored in <code class="docutils literal notranslate"><span class="pre">resnet50-v2-7-autotuner_records.json</span></code>. This file can be used in
two ways:</p>
<ul class="simple">
<li><p>As input to further tuning (via <code class="docutils literal notranslate"><span class="pre">tvmc</span> <span class="pre">tune</span> <span class="pre">--tuning-records</span></code>).</p></li>
<li><p>As input to the compiler</p></li>
</ul>
<p>The compiler will use the results to generate high performance code for the
model on your specified target. To do that we can use <code class="docutils literal notranslate"><span class="pre">tvmc</span> <span class="pre">compile</span>
<span class="pre">--tuning-records</span></code>. Check <code class="docutils literal notranslate"><span class="pre">tvmc</span> <span class="pre">compile</span> <span class="pre">--help</span></code> for more information.</p>
<p>Now that tuning data for the model has been collected, we can re-compile the
model using optimized operators to speed up our computations.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>tvmc compile <span class="se">\</span>
--target <span class="s2">&quot;llvm&quot;</span> <span class="se">\</span>
--tuning-records resnet50-v2-7-autotuner_records.json  <span class="se">\</span>
--output resnet50-v2-7-tvm_autotuned.tar <span class="se">\</span>
resnet50-v2-7.onnx
</pre></div>
</div>
<p>Verify that the optimized model runs and produces the same results:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>tvmc run <span class="se">\</span>
--inputs imagenet_cat.npz <span class="se">\</span>
--output predictions.npz <span class="se">\</span>
resnet50-v2-7-tvm_autotuned.tar

python postprocess.py
</pre></div>
</div>
<p>Verifying that the predictions are the same:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># class=&#39;n02123045 tabby, tabby cat&#39; with probability=0.610550</span>
<span class="c1"># class=&#39;n02123159 tiger cat&#39; with probability=0.367181</span>
<span class="c1"># class=&#39;n02124075 Egyptian cat&#39; with probability=0.019365</span>
<span class="c1"># class=&#39;n02129604 tiger, Panthera tigris&#39; with probability=0.001273</span>
<span class="c1"># class=&#39;n04040759 radiator&#39; with probability=0.000261</span>
</pre></div>
</div>
</div>
<div class="section" id="comparing-the-tuned-and-untuned-models">
<h2>Comparing the Tuned and Untuned Models<a class="headerlink" href="#comparing-the-tuned-and-untuned-models" title="永久链接至标题">¶</a></h2>
<p>TVMC gives you tools for basic performance benchmarking between the models.
You can specify a number of repetitions and that TVMC report on the model run
time (independent of runtime startup). We can get a rough idea of how much
tuning has improved the model performance. For example, on a test Intel i7
system, we see that the tuned model runs 47% faster than the untuned model:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>tvmc run <span class="se">\</span>
--inputs imagenet_cat.npz <span class="se">\</span>
--output predictions.npz  <span class="se">\</span>
--print-time <span class="se">\</span>
--repeat <span class="m">100</span> <span class="se">\</span>
resnet50-v2-7-tvm_autotuned.tar

<span class="c1"># Execution time summary:</span>
<span class="c1"># mean (ms)   max (ms)    min (ms)    std (ms)</span>
<span class="c1">#     92.19     115.73       89.85        3.15</span>

tvmc run <span class="se">\</span>
--inputs imagenet_cat.npz <span class="se">\</span>
--output predictions.npz  <span class="se">\</span>
--print-time <span class="se">\</span>
--repeat <span class="m">100</span> <span class="se">\</span>
resnet50-v2-7-tvm.tar

<span class="c1"># Execution time summary:</span>
<span class="c1"># mean (ms)   max (ms)    min (ms)    std (ms)</span>
<span class="c1">#    193.32     219.97      185.04        7.11</span>
</pre></div>
</div>
</div>
<div class="section" id="final-remarks">
<h2>Final Remarks<a class="headerlink" href="#final-remarks" title="永久链接至标题">¶</a></h2>
<p>In this tutorial, we presented TVMC, a command line driver for TVM. We
demonstrated how to compile, run, and tune a model. We also discussed the
need for pre and post-processing of inputs and outputs. After the tuning
process, we demonstrated how to compare the performance of the unoptimized
and optimize models.</p>
<p>Here we presented a simple example using ResNet 50 V2 locally. However, TVMC
supports many more features including cross-compilation, remote execution and
profiling/benchmarking.</p>
<p>To see what other options are available, please have a look at <code class="docutils literal notranslate"><span class="pre">tvmc</span>
<span class="pre">--help</span></code>.</p>
<p>In the next tutorial, <a class="reference external" href="auto_tuning_with_pyton">Compiling and Optimizing a Model with the Python
Interface</a>, we will cover the same compilation
and optimization steps using the Python interface.</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-tutorials-get-started-tvmc-command-line-driver-py">
<div class="sphx-glr-download docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/18fb1ab3ed0a0c9f304520f2beaf4fd6/tvmc_command_line_driver.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">tvmc_command_line_driver.py</span></code></a></p>
</div>
<div class="sphx-glr-download docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/dfa0880631b34bb8814952afdc9031d8/tvmc_command_line_driver.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">tvmc_command_line_driver.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>


           </div>
           
          </div>
          

<footer>

    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="autotvm_relay_x86.html" class="btn btn-neutral float-right" title="Compiling and Optimizing a Model with the Python Interface (AutoTVM)" accesskey="n" rel="next">下一个 <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="install.html" class="btn btn-neutral float-left" title="安装 TVM" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> 上一个</a>
      
    </div>

<div id="button" class="backtop"><img src="../../_static//img/right.svg" alt="backtop"/> </div>
<section class="footerSec">
    <div class="footerHeader">
      <ul class="d-flex align-md-items-center justify-content-between flex-column flex-md-row">
        <li class="copywrite d-flex align-items-center">
          <h5 id="copy-right-info">© 2020 Apache Software Foundation | All right reserved</h5>
        </li>
      </ul>

    </div>

    <ul>
      <li class="footernote">Copyright © 2020 The Apache Software Foundation. Apache TVM, Apache, the Apache feather, and the Apache TVM project logo are either trademarks or registered trademarks of the Apache Software Foundation.</li>
    </ul>

</section>
</footer>
        </div>
      </div>

    </section>

  </div>
  

    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js" integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q" crossorigin="anonymous"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js" integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl" crossorigin="anonymous"></script>

  </body>
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
    <!-- Theme Analytics -->
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-75982049-2', 'auto');
    ga('send', 'pageview');
    </script>

    
   

</body>
</html>